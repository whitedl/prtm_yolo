{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import csv\n",
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Roboflow.com to build training models. Copy code from Roboflow annotation tool. Will download the data to location of script, using the API_KEY that is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in prtm_virgina-4 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 920/920 [00:00<00:00, 7057.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to prtm_virgina-4 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 1987.45it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\"\"\" from roboflow import Roboflow \"\"\"\n",
    "\"\"\" rf = Roboflow(api_key=\"RTMVUfvcIxv0eaah6DF9\") \"\"\"\n",
    "\"\"\" project = rf.workspace(\"davidlwhite100-gmail-com\").project(\"prtm_virgina\") \"\"\"\n",
    "\"\"\" version = project.version(1) \"\"\"\n",
    "\"\"\" dataset = version.download(\"coco\") \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" # Roboflow Version 3 - Human 9 images \"\"\"\n",
    "\"\"\" from roboflow import Roboflow \"\"\"\n",
    "\"\"\" rf = Roboflow(api_key=\"RTMVUfvcIxv0eaah6DF9\") \"\"\"\n",
    "\"\"\" project = rf.workspace(\"prtm\").project(\"prtm_virgina\") \"\"\"\n",
    "\"\"\" version = project.version(2) \"\"\"\n",
    "\"\"\" dataset = version.download(\"yolov8\") \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" # Roboflow Version 4 - Human and People \"\"\"\n",
    "\"\"\" rf = Roboflow(api_key=\"RTMVUfvcIxv0eaah6DF9\") \"\"\"\n",
    "\"\"\" project = rf.workspace(\"prtm\").project(\"prtm_virgina\") \"\"\"\n",
    "\"\"\" version = project.version(4) \"\"\"\n",
    "\"\"\" dataset = version.download(\"yolov8\") \"\"\"\n",
    "\"\"\"  \"\"\"\n",
    "\n",
    "# Roboflow Version 4 - Human and People and Boat\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"RTMVUfvcIxv0eaah6DF9\")\n",
    "project = rf.workspace(\"prtm\").project(\"prtm_virgina\")\n",
    "version = project.version(5)\n",
    "dataset = version.download(\"yolov8\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model \n",
    "A YOLO .pt file is a model file used for the YOLO (You Only Look Once) object detection algorithm. Specifically, it is a PyTorch model file that contains a pre-trained model.\n",
    "\n",
    "Key Components of a .pt File:\n",
    "- Model Weights: It stores the learned parameters (weights) of the YOLO model, which are adjusted during the training process. These weights help the model detect objects in images.\n",
    "- Model Architecture: It also contains the architecture of the YOLO network (such as YOLOv8, YOLOv5, etc.). This defines the structure of the layers, the number of neurons, and other important architectural details.\n",
    "\n",
    "Pre-trained or Custom Model:\n",
    "- Pre-trained models: These are YOLO models trained on large datasets like COCO, which can be fine-tuned for specific use cases.\n",
    "- Custom models: These .pt files can also be generated after training the YOLO model on custom datasets for specific object detection tasks (e.g., detecting specific objects like cars, humans, etc.).\n",
    "- Inference Ready: The .pt file is used for both training and inference. You can load it into a YOLO implementation (using PyTorch) and directly use it to detect objects in images or video.\n",
    "\n",
    "Multiple versions for YOLOv8: \n",
    "- yolov8n.pt (nano) is primarily used for test and code development. Fast.\n",
    "- yolov8s.pt (small) is a balance between size and performance, this is still lightweight but slightly more capable than the Nano model.\n",
    "- Additional models incresing in size and complexity (medium, large, and extra-large). More time is required to train as you step up in model variants.\n",
    "\n",
    "Time requirements:\n",
    "- Using yolov8s.pt with Roboflow version 4 training data (humans and people) with 100 epochs. The training took ~30 minutes on a MAC M1 processor. \n",
    "- For testing use yolovn.pt for debugging and preformance review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.95 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.12.6 torch-2.2.2 CPU (Apple M1)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/Users/davidwhite/Yolo_Code/prtm_yolo/Code/prtm_virgina-4/data.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/train, name=custom_yolo8s_experiment_ver4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/train/custom_yolo8s_experiment_ver4\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11136374 parameters, 11136358 gradients\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/davidwhite/Yolo_Code/prtm_yolo/Code/prtm_virgina-4/train/labels... 15 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 2297.83it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/davidwhite/Yolo_Code/prtm_yolo/Code/prtm_virgina-4/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/davidwhite/Yolo_Code/prtm_yolo/Code/prtm_virgina-4/valid/labels... 3 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 1912.59it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/davidwhite/Yolo_Code/prtm_yolo/Code/prtm_virgina-4/valid/labels.cache\n",
      "Plotting labels to runs/train/custom_yolo8s_experiment_ver4/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/custom_yolo8s_experiment_ver4\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100         0G      2.562      3.363      1.412        270        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.16it/s]\n",
      "                   all          3         47      0.683      0.239      0.182     0.0671\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100         0G      2.742      3.477      1.491        290        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.27it/s]\n",
      "                   all          3         47      0.689      0.227      0.186     0.0696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100         0G      2.752       3.25      1.426        291        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.27it/s]\n",
      "                   all          3         47       0.74      0.241      0.222     0.0716\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100         0G      2.552      3.025      1.307        222        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                   all          3         47       0.77      0.213      0.218     0.0703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100         0G      2.434      2.359      1.308        248        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.34it/s]\n",
      "                   all          3         47      0.874      0.202      0.241     0.0775\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100         0G      2.385      2.189      1.256        274        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.27it/s]\n",
      "                   all          3         47      0.781      0.284      0.269      0.092\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100         0G      2.205      1.921      1.133        263        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                   all          3         47       0.79      0.235      0.251     0.0997\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100         0G      2.287      1.858      1.161        319        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                   all          3         47      0.807      0.236      0.246     0.0964\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100         0G      2.369      1.916      1.187        242        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                   all          3         47      0.752       0.25      0.227     0.0951\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100         0G      2.085      1.641      1.097        280        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                   all          3         47      0.776      0.294      0.258      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100         0G      2.125      1.729       1.09        189        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.19it/s]\n",
      "                   all          3         47      0.756      0.307      0.264       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100         0G      2.072      1.521      1.113        294        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                   all          3         47      0.782      0.273       0.29      0.115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100         0G      2.077      1.538      1.106        230        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                   all          3         47      0.279      0.542       0.36      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100         0G      1.907      1.446      1.037        198        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.39it/s]\n",
      "                   all          3         47      0.349      0.456      0.334      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100         0G      2.021      1.625      1.065        190        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                   all          3         47      0.271      0.283      0.294      0.114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100         0G      2.086      1.605      1.024        234        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.30it/s]\n",
      "                   all          3         47      0.271      0.273      0.272      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100         0G      1.851      1.353      1.008        217        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.32it/s]\n",
      "                   all          3         47      0.817      0.284      0.264     0.0964\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100         0G      1.762      1.341      1.033        190        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.19it/s]\n",
      "                   all          3         47      0.817      0.284      0.264     0.0964\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100         0G      2.006      1.495      1.046        236        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all          3         47      0.782      0.318      0.284     0.0993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100         0G       1.78      1.211      1.032        234        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          3         47      0.782      0.318      0.284     0.0993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100         0G        1.9      1.213      1.052        326        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.40s/it]\n",
      "                   all          3         47      0.837      0.282      0.297      0.112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100         0G      1.807      1.216     0.9854        266        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.13it/s]\n",
      "                   all          3         47      0.837      0.282      0.297      0.112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100         0G      1.827      1.225      1.045        240        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                   all          3         47      0.256      0.286      0.256     0.0971\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100         0G      1.784      1.244      1.015        316        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.84s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.11it/s]\n",
      "                   all          3         47      0.256      0.286      0.256     0.0971\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100         0G      1.874       1.18       1.04        306        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                   all          3         47      0.286      0.284      0.247     0.0911\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100         0G      1.695      1.097          1        278        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          3         47      0.286      0.284      0.247     0.0911\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100         0G      1.767      1.133      1.072        224        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.20it/s]\n",
      "                   all          3         47      0.302      0.284      0.256      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100         0G      1.942      1.241     0.9874        330        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          3         47      0.302      0.284      0.256      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100         0G      1.766       1.12      1.036        258        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.26it/s]\n",
      "                   all          3         47      0.255      0.496      0.283      0.122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100         0G      1.712      1.293      1.026        215        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.15s/it]\n",
      "                   all          3         47      0.255      0.496      0.283      0.122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100         0G      1.695       1.16      1.006        256        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.18it/s]\n",
      "                   all          3         47      0.311      0.439      0.241      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100         0G      1.638      1.028     0.9909        243        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                   all          3         47      0.311      0.439      0.241      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100         0G      1.538      1.001     0.9769        190        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.28it/s]\n",
      "                   all          3         47      0.258      0.334      0.217     0.0808\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100         0G      1.583      1.259     0.9893        231        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                   all          3         47      0.258      0.334      0.217     0.0808\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/100         0G      1.713      1.195      1.017        220        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.35it/s]\n",
      "                   all          3         47      0.331      0.269      0.267     0.0772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/100         0G      1.841      1.209      1.009        245        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                   all          3         47      0.331      0.269      0.267     0.0772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/100         0G      1.804      1.211     0.9906        310        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                   all          3         47      0.371      0.337      0.217     0.0709\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/100         0G      1.732       1.05     0.9787        330        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                   all          3         47      0.371      0.337      0.217     0.0709\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/100         0G       1.66      1.075      1.024        198        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                   all          3         47        0.3      0.405       0.24     0.0824\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/100         0G      1.599      1.102      1.012        180        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                   all          3         47        0.3      0.405       0.24     0.0824\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/100         0G      1.676      1.179     0.9724        224        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.36it/s]\n",
      "                   all          3         47      0.328      0.538      0.282     0.0866\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/100         0G      1.637      1.033      1.048        186        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          3         47      0.328      0.538      0.282     0.0866\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/100         0G      1.767      1.042      1.098        194        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.43it/s]\n",
      "                   all          3         47       0.39      0.583      0.399       0.17\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/100         0G      1.733      1.116      1.039        255        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                   all          3         47       0.39      0.583      0.399       0.17\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/100         0G      1.711      1.053     0.9781        341        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.24it/s]\n",
      "                   all          3         47      0.487      0.473      0.385      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/100         0G      1.697      1.093     0.9579        257        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.12it/s]\n",
      "                   all          3         47      0.487      0.473      0.385      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/100         0G      1.716      1.103      1.013        174        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.41it/s]\n",
      "                   all          3         47      0.407       0.53      0.425      0.198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/100         0G      1.771       1.06     0.9606        289        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.16it/s]\n",
      "                   all          3         47      0.407       0.53      0.425      0.198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/100         0G      1.643      1.015      1.012        311        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                   all          3         47      0.467      0.553      0.464      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/100         0G      1.704     0.9695     0.9924        360        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.84s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                   all          3         47      0.467      0.553      0.464      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/100         0G      1.682     0.9927     0.9387        344        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                   all          3         47      0.524      0.542      0.471      0.228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/100         0G      1.538      1.017      1.002        182        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                   all          3         47      0.524      0.542      0.471      0.228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/100         0G      1.701      1.017     0.9687        254        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.22it/s]\n",
      "                   all          3         47      0.524      0.542      0.471      0.228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/100         0G      1.653     0.9734     0.9439        343        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                   all          3         47      0.574      0.523       0.49      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/100         0G      1.703     0.9762     0.9742        311        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.11it/s]\n",
      "                   all          3         47      0.574      0.523       0.49      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/100         0G      1.711     0.9506      0.957        335        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.18it/s]\n",
      "                   all          3         47      0.574      0.523       0.49      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/100         0G      1.588     0.9216      0.949        356        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all          3         47      0.894      0.625       0.69      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/100         0G      1.637     0.9173     0.9456        294        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.19it/s]\n",
      "                   all          3         47      0.894      0.625       0.69      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/100         0G      1.701     0.9548     0.9759        238        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.98s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.12it/s]\n",
      "                   all          3         47      0.894      0.625       0.69      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/100         0G      1.696      0.957      0.977        246        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                   all          3         47      0.675      0.686      0.665      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/100         0G      1.529     0.8902     0.9145        272        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.20s/it]\n",
      "                   all          3         47      0.675      0.686      0.665      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/100         0G      1.502     0.9438     0.9273        258        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          3         47      0.675      0.686      0.665      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/100         0G       1.53     0.9267     0.9261        360        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.17s/it]\n",
      "                   all          3         47      0.668      0.498      0.619      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/100         0G      1.554     0.8852     0.9379        311        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.04it/s]\n",
      "                   all          3         47      0.668      0.498      0.619      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/100         0G      1.541     0.8715     0.9564        271        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.17it/s]\n",
      "                   all          3         47      0.668      0.498      0.619      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/100         0G      1.561      0.889      0.965        337        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all          3         47      0.603      0.564      0.602      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/100         0G      1.657     0.9841       0.97        307        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.16it/s]\n",
      "                   all          3         47      0.603      0.564      0.602      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/100         0G      1.492     0.9507     0.9699        241        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.19it/s]\n",
      "                   all          3         47      0.603      0.564      0.602      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/100         0G      1.551     0.9887       0.93        299        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.25it/s]\n",
      "                   all          3         47      0.389      0.587      0.485      0.213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/100         0G       1.79        1.1     0.9582        291        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.13it/s]\n",
      "                   all          3         47      0.389      0.587      0.485      0.213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/100         0G      2.245       1.23       0.97        461        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.12it/s]\n",
      "                   all          3         47      0.389      0.587      0.485      0.213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/100         0G      1.402     0.8567     0.9346        254        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all          3         47      0.418      0.564      0.469        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/100         0G      1.579     0.8848     0.9425        273        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.98s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.13it/s]\n",
      "                   all          3         47      0.418      0.564      0.469        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/100         0G      1.507     0.8731     0.9546        272        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.13it/s]\n",
      "                   all          3         47      0.418      0.564      0.469        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/100         0G      1.397     0.8266      0.958        233        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.33it/s]\n",
      "                   all          3         47      0.582      0.509      0.477      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     76/100         0G      1.477     0.8821      0.982        225        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                   all          3         47      0.582      0.509      0.477      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     77/100         0G      1.627     0.8735     0.9774        239        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.19it/s]\n",
      "                   all          3         47      0.582      0.509      0.477      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     78/100         0G      1.486     0.8405     0.9232        325        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.20it/s]\n",
      "                   all          3         47      0.607      0.508      0.482        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     79/100         0G      1.456     0.8366     0.9367        261        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.84s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.04it/s]\n",
      "                   all          3         47      0.607      0.508      0.482        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     80/100         0G      1.485     0.9184     0.9297        340        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.10it/s]\n",
      "                   all          3         47      0.607      0.508      0.482        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     81/100         0G      1.486     0.8983     0.9253        253        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.31it/s]\n",
      "                   all          3         47      0.789      0.455      0.565      0.194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     82/100         0G      1.498     0.9023      0.924        319        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.01it/s]\n",
      "                   all          3         47      0.789      0.455      0.565      0.194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     83/100         0G      1.575     0.8782     0.9368        280        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.59s/it]\n",
      "                   all          3         47      0.789      0.455      0.565      0.194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     84/100         0G      1.454       0.85     0.9379        264        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.38it/s]\n",
      "                   all          3         47      0.692      0.462      0.584      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     85/100         0G      1.374     0.7984     0.9481        227        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.03it/s]\n",
      "                   all          3         47      0.692      0.462      0.584      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     86/100         0G      1.411     0.8005     0.8995        315        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          3         47      0.692      0.462      0.584      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     87/100         0G       1.43      0.844      0.959        171        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.13it/s]\n",
      "                   all          3         47      0.692      0.462      0.584      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     88/100         0G       1.35     0.7739     0.8943        245        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.12it/s]\n",
      "                   all          3         47       0.66      0.499      0.613      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     89/100         0G      1.462     0.8785     0.9488        238        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.20it/s]\n",
      "                   all          3         47       0.66      0.499      0.613      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     90/100         0G      1.375     0.7765     0.9123        294        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.65s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s]\n",
      "                   all          3         47       0.66      0.499      0.613      0.296\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     91/100         0G      1.438     0.8793     0.9542        180        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          3         47       0.66      0.499      0.613      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     92/100         0G      1.461     0.8561      1.001        180        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                   all          3         47      0.719      0.483      0.601      0.335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     93/100         0G      1.438     0.8693     0.9397        177        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.00it/s]\n",
      "                   all          3         47      0.719      0.483      0.601      0.335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     94/100         0G      1.347     0.7998     0.9133        177        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.00it/s]\n",
      "                   all          3         47      0.719      0.483      0.601      0.335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     95/100         0G      1.362     0.7742     0.9625        172        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.15it/s]\n",
      "                   all          3         47      0.719      0.483      0.601      0.335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     96/100         0G      1.434     0.8284     0.9501        196        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.37it/s]\n",
      "                   all          3         47      0.815      0.473       0.61      0.327\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     97/100         0G      1.474     0.8047     0.9706        182        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.18it/s]\n",
      "                   all          3         47      0.815      0.473       0.61      0.327\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     98/100         0G      1.443     0.8339     0.9576        176        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                   all          3         47      0.815      0.473       0.61      0.327\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     99/100         0G      1.426     0.8052     0.9694        182        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s]\n",
      "                   all          3         47      0.815      0.473       0.61      0.327\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    100/100         0G      1.297     0.7546     0.9827        173        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.42it/s]\n",
      "                   all          3         47      0.828      0.473      0.603      0.323\n",
      "\n",
      "100 epochs completed in 0.494 hours.\n",
      "Optimizer stripped from runs/train/custom_yolo8s_experiment_ver4/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/train/custom_yolo8s_experiment_ver4/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/train/custom_yolo8s_experiment_ver4/weights/best.pt...\n",
      "Python(51315) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.12.6 torch-2.2.2 CPU (Apple M1)\n",
      "Model summary (fused): 168 layers, 11126358 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.56it/s]\n",
      "                   all          3         47      0.721      0.483      0.601      0.318\n",
      "                 Human          3         44      0.874      0.633       0.77      0.388\n",
      "                People          3          3      0.567      0.333      0.431      0.249\n",
      "Speed: 1.5ms preprocess, 203.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/train/custom_yolo8s_experiment_ver4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Using YOLOv8. A number of different models to use. \n",
    "# Load the YOLOv8 small model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model using your custom dataset. Review \"data.yaml\" description and detection objects\n",
    "results = model.train(\n",
    "    data=f'/Users/davidwhite/Yolo_Code/prtm_yolo/Code/prtm_virgina-4/data.yaml',  # Path to the dataset YAML file. Needs to be UPDATED with NEW TRAINING DATA\n",
    "    epochs=100,                            # Number of epochs to train\n",
    "    imgsz=640,                             # Image size\n",
    "    project='runs/train',                  # Directory where models are saved\n",
    "    name='custom_yolo8s_experiment_ver4'   # Name for the experiment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "results = model.train(data=\"coco8.yaml\", epochs=100, imgsz=640)\n",
    "\n",
    "# results = model.train(source=Path('~/Yolo_Code/prtm_yolo/datasets/coco8.yaml').expanduser(), save=True)\n",
    "\n",
    "\n",
    "\"\"\" model.train( \"\"\"\n",
    "\"\"\" epochs=100,         # Increase or decrease based on your needs \"\"\"\n",
    "\"\"\"     batch=16,           # Adjust based on available GPU memory \"\"\"\n",
    "\"\"\"     imgsz=640,          # Try different sizes (e.g., 416, 512, 640) \"\"\"\n",
    "\"\"\"     lr0=0.01,           # Initial learning rate (experiment with different values) \"\"\"\n",
    "\"\"\"     lrf=0.1,            # Final learning rate (if using a learning rate scheduler) \"\"\"\n",
    "\"\"\"     momentum=0.937,     # Momentum (adjust as needed) \"\"\"\n",
    "\"\"\"     weight_decay=0.0005, # Regularization parameter \"\"\"\n",
    "\"\"\"     name='yolov8n_experiment', \"\"\"\n",
    "\"\"\"     save_period=10,     # Save checkpoints every N epochs \"\"\"\n",
    "\"\"\"     augment=True        # Use data augmentation \"\"\"\n",
    "\"\"\" ) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/davidwhite/Yolo_Code/prtm_yolo/datasets/fh.png\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder containing images\n",
    "#image_path = '/Users/davidwhite/Yolo_Code/prtm_yolo/datasets'\n",
    "image_path = Path('~/Yolo_Code/prtm_yolo/datasets/fh.png').expanduser()\n",
    "image_path = str(image_path)\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on a single image\n",
    "results = model.predict(source=Path('~/Yolo_Code/prtm_yolo/datasets/fh.png').expanduser(), save=True)\n",
    "\n",
    "# Extract detection details\n",
    "detection_data = []\n",
    "for result in results:\n",
    "    for detection in result.boxes.data:\n",
    "        x1, y1, x2, y2, confidence, class_id = detection[:6]\n",
    "        detection_data.append([x1.item(), y1.item(), x2.item(), y2.item(), confidence.item(), int(class_id)])\n",
    "\n",
    "# Save detection results to CSV\n",
    "csv_filename = 'detections.csv'\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # Write the header\n",
    "    csvwriter.writerow(['x1', 'y1', 'x2', 'y2', 'confidence', 'class_id'])\n",
    "    # Write detection data\n",
    "    csvwriter.writerows(detection_data)\n",
    "\n",
    "\"\"\" # Optional: Display the image with detections (for visualization) \"\"\"\n",
    "\"\"\" image = cv2.imread(image_path) \"\"\"\n",
    "\"\"\" for detection in detection_data: \"\"\"\n",
    "\"\"\"     x1, y1, x2, y2 = map(int, detection[:4]) \"\"\"\n",
    "\"\"\"     cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw bounding box \"\"\"\n",
    "\"\"\"  \"\"\"\n",
    "\"\"\" cv2.imshow('YOLO Detections', image) \"\"\"\n",
    "\"\"\" cv2.waitKey(0) \"\"\"\n",
    "\"\"\" cv2.destroyAllWindows() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder containing images\n",
    "\n",
    "# For MAC, change to folder location\n",
    "# image_folder = '/Users/davidwhite/Yolo_Code/prtm_yolo/datasets/test'\n",
    "\n",
    "# For MAC, change to your folder location. Identifies home directory (i.e., /Users/davidwhite/Yolo_Code/prtm_yolo/.....)\n",
    "image_folder = Path('~/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/').expanduser()\n",
    "# Converts to a string\n",
    "image_folder = str(image_folder)\n",
    "# Verify thge folder is correct\n",
    "print(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach\n"
     ]
    }
   ],
   "source": [
    "# Folder to save all output images PC\n",
    "#output_folder = r'D:\\Yolo_Code\\prtm_yolo\\runs\\detect\\out_beach'\n",
    "\n",
    "# Folder to save all output images MAC. Identifies home directory (i.e., /Users/davidwhite/Yolo_Code/runs/.....).\n",
    "# Use simple path specfication if this does not work. See above.\n",
    "output_folder = Path('~/Yolo_Code/prtm_yolo/runs/detect/out_beach').expanduser()\n",
    "# If folder does not exist it will create\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "# Converts to a string\n",
    "output_folder = str(output_folder)\n",
    "# Verify the folder is correct\n",
    "print(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(51384) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "\n",
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9348.JPG: 384x640 8 Humans, 197.0ms\n",
      "Speed: 9.1ms preprocess, 197.0ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9348.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9275.JPG: 384x640 12 Humans, 143.2ms\n",
      "Speed: 2.0ms preprocess, 143.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9275.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9261.JPG: 384x640 22 Humans, 205.1ms\n",
      "Speed: 2.9ms preprocess, 205.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9261.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9329.JPG: 384x640 9 Humans, 188.0ms\n",
      "Speed: 6.8ms preprocess, 188.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9329.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9301.JPG: 384x640 18 Humans, 146.4ms\n",
      "Speed: 2.8ms preprocess, 146.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9301.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9315.JPG: 384x640 24 Humans, 148.0ms\n",
      "Speed: 2.2ms preprocess, 148.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9315.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9314.JPG: 384x640 31 Humans, 120.8ms\n",
      "Speed: 1.9ms preprocess, 120.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9314.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9300.JPG: 384x640 8 Humans, 136.4ms\n",
      "Speed: 2.3ms preprocess, 136.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9300.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9328.JPG: 384x640 17 Humans, 136.2ms\n",
      "Speed: 2.1ms preprocess, 136.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9328.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9260.JPG: 384x640 16 Humans, 135.2ms\n",
      "Speed: 5.4ms preprocess, 135.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9260.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9274.JPG: 384x640 13 Humans, 117.4ms\n",
      "Speed: 2.4ms preprocess, 117.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9274.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9262.JPG: 384x640 27 Humans, 157.6ms\n",
      "Speed: 2.0ms preprocess, 157.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9262.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9276.JPG: 384x640 3 Humans, 162.1ms\n",
      "Speed: 2.2ms preprocess, 162.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9276.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9289.JPG: 384x640 8 Humans, 143.9ms\n",
      "Speed: 2.7ms preprocess, 143.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9289.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9316.JPG: 384x640 22 Humans, 153.4ms\n",
      "Speed: 5.2ms preprocess, 153.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9316.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9302.JPG: 384x640 8 Humans, 130.2ms\n",
      "Speed: 2.5ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9302.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9303.JPG: 384x640 3 Humans, 241.4ms\n",
      "Speed: 2.3ms preprocess, 241.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9303.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9317.JPG: 384x640 23 Humans, 186.8ms\n",
      "Speed: 4.9ms preprocess, 186.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9317.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9288.JPG: 384x640 35 Humans, 231.7ms\n",
      "Speed: 2.3ms preprocess, 231.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9288.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9277.JPG: 384x640 9 Humans, 164.0ms\n",
      "Speed: 4.6ms preprocess, 164.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9277.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9263.JPG: 384x640 11 Humans, 143.4ms\n",
      "Speed: 2.2ms preprocess, 143.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9263.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9267.JPG: 384x640 15 Humans, 157.6ms\n",
      "Speed: 2.6ms preprocess, 157.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9267.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9273.JPG: 384x640 9 Humans, 166.5ms\n",
      "Speed: 2.1ms preprocess, 166.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9273.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9298.JPG: 384x640 31 Humans, 146.4ms\n",
      "Speed: 3.0ms preprocess, 146.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9298.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9313.JPG: 384x640 20 Humans, 130.3ms\n",
      "Speed: 1.9ms preprocess, 130.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9313.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9307.JPG: 384x640 13 Humans, 168.6ms\n",
      "Speed: 4.2ms preprocess, 168.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9307.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9306.JPG: 384x640 18 Humans, 139.7ms\n",
      "Speed: 2.3ms preprocess, 139.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9306.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9312.JPG: 384x640 10 Humans, 142.2ms\n",
      "Speed: 2.3ms preprocess, 142.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9312.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9299.JPG: 384x640 15 Humans, 132.3ms\n",
      "Speed: 5.2ms preprocess, 132.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9299.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9272.JPG: 384x640 16 Humans, 133.5ms\n",
      "Speed: 2.1ms preprocess, 133.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9272.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9266.JPG: 384x640 15 Humans, 172.9ms\n",
      "Speed: 2.9ms preprocess, 172.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9266.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9270.JPG: 384x640 26 Humans, 147.9ms\n",
      "Speed: 2.5ms preprocess, 147.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9270.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9264.JPG: 384x640 22 Humans, 122.9ms\n",
      "Speed: 2.0ms preprocess, 122.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9264.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9258.JPG: 384x640 18 Humans, 158.6ms\n",
      "Speed: 2.9ms preprocess, 158.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9258.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9304.JPG: 384x640 8 Humans, 174.9ms\n",
      "Speed: 9.4ms preprocess, 174.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9304.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9310.JPG: 384x640 23 Humans, 134.3ms\n",
      "Speed: 3.5ms preprocess, 134.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9310.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9338.JPG: 384x640 12 Humans, 127.6ms\n",
      "Speed: 2.1ms preprocess, 127.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9338.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9339.JPG: 384x640 12 Humans, 139.8ms\n",
      "Speed: 3.9ms preprocess, 139.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9339.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9311.JPG: 384x640 13 Humans, 136.4ms\n",
      "Speed: 2.0ms preprocess, 136.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9311.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9305.JPG: 384x640 11 Humans, 126.1ms\n",
      "Speed: 2.2ms preprocess, 126.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9305.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9259.JPG: 384x640 24 Humans, 119.5ms\n",
      "Speed: 2.0ms preprocess, 119.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9259.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9265.JPG: 384x640 26 Humans, 125.6ms\n",
      "Speed: 2.2ms preprocess, 125.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9265.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9271.JPG: 384x640 23 Humans, 108.6ms\n",
      "Speed: 2.1ms preprocess, 108.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9271.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9268.JPG: 384x640 15 Humans, 118.4ms\n",
      "Speed: 2.2ms preprocess, 118.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9268.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9254.JPG: 384x640 22 Humans, 254.8ms\n",
      "Speed: 3.3ms preprocess, 254.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9254.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9297.JPG: 384x640 31 Humans, 140.4ms\n",
      "Speed: 2.7ms preprocess, 140.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9297.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9283.JPG: 384x640 26 Humans, 149.7ms\n",
      "Speed: 3.0ms preprocess, 149.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9283.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9308.JPG: 384x640 15 Humans, 141.1ms\n",
      "Speed: 2.2ms preprocess, 141.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9308.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9320.JPG: 384x640 21 Humans, 151.3ms\n",
      "Speed: 2.2ms preprocess, 151.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9320.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9334.JPG: 384x640 (no detections), 169.1ms\n",
      "Speed: 3.1ms preprocess, 169.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9334.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9335.JPG: 384x640 2 Humans, 132.5ms\n",
      "Speed: 2.3ms preprocess, 132.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9335.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9321.JPG: 384x640 20 Humans, 130.8ms\n",
      "Speed: 2.5ms preprocess, 130.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9321.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9309.JPG: 384x640 26 Humans, 148.3ms\n",
      "Speed: 3.5ms preprocess, 148.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9309.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9282.JPG: 384x640 17 Humans, 156.9ms\n",
      "Speed: 3.5ms preprocess, 156.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9282.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9296.JPG: 384x640 15 Humans, 159.0ms\n",
      "Speed: 3.8ms preprocess, 159.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9296.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9255.JPG: 384x640 15 Humans, 148.4ms\n",
      "Speed: 2.3ms preprocess, 148.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9255.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9269.JPG: 384x640 21 Humans, 143.8ms\n",
      "Speed: 3.0ms preprocess, 143.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9269.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9257.JPG: 384x640 19 Humans, 133.7ms\n",
      "Speed: 2.2ms preprocess, 133.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9257.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9280.JPG: 384x640 38 Humans, 202.9ms\n",
      "Speed: 1.8ms preprocess, 202.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9280.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9294.JPG: 384x640 22 Humans, 142.0ms\n",
      "Speed: 2.3ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9294.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9337.JPG: 384x640 1 Human, 122.0ms\n",
      "Speed: 2.2ms preprocess, 122.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9337.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9323.JPG: 384x640 22 Humans, 124.7ms\n",
      "Speed: 2.0ms preprocess, 124.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9323.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9322.JPG: 384x640 14 Humans, 122.3ms\n",
      "Speed: 2.0ms preprocess, 122.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9322.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9336.JPG: 384x640 5 Humans, 122.9ms\n",
      "Speed: 1.8ms preprocess, 122.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9336.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9295.JPG: 384x640 18 Humans, 124.0ms\n",
      "Speed: 2.1ms preprocess, 124.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9295.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9281.JPG: 384x640 33 Humans, 109.2ms\n",
      "Speed: 2.0ms preprocess, 109.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9281.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9256.JPG: 384x640 15 Humans, 156.0ms\n",
      "Speed: 1.9ms preprocess, 156.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9256.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9285.JPG: 384x640 15 Humans, 124.0ms\n",
      "Speed: 2.0ms preprocess, 124.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9285.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9291.JPG: 384x640 15 Humans, 136.5ms\n",
      "Speed: 2.0ms preprocess, 136.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9291.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9332.JPG: 384x640 2 Humans, 136.4ms\n",
      "Speed: 1.8ms preprocess, 136.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9332.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9326.JPG: 384x640 38 Humans, 1 People, 130.7ms\n",
      "Speed: 2.2ms preprocess, 130.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9326.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9327.JPG: 384x640 14 Humans, 132.9ms\n",
      "Speed: 2.3ms preprocess, 132.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9327.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9333.JPG: 384x640 1 Human, 148.8ms\n",
      "Speed: 2.5ms preprocess, 148.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9333.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9290.JPG: 384x640 18 Humans, 134.0ms\n",
      "Speed: 2.1ms preprocess, 134.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9290.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9284.JPG: 384x640 22 Humans, 141.7ms\n",
      "Speed: 2.3ms preprocess, 141.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9284.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9279.JPG: 384x640 16 Humans, 131.5ms\n",
      "Speed: 2.5ms preprocess, 131.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9279.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9292.JPG: 384x640 18 Humans, 110.6ms\n",
      "Speed: 5.0ms preprocess, 110.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9292.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9286.JPG: 384x640 25 Humans, 123.9ms\n",
      "Speed: 1.9ms preprocess, 123.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9286.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9325.JPG: 384x640 26 Humans, 114.5ms\n",
      "Speed: 1.7ms preprocess, 114.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9325.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9331.JPG: 384x640 2 Humans, 134.0ms\n",
      "Speed: 1.9ms preprocess, 134.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9331.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9319.JPG: 384x640 42 Humans, 130.7ms\n",
      "Speed: 2.2ms preprocess, 130.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9319.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9318.JPG: 384x640 26 Humans, 145.2ms\n",
      "Speed: 2.1ms preprocess, 145.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9318.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9330.JPG: 384x640 10 Humans, 143.6ms\n",
      "Speed: 2.4ms preprocess, 143.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9330.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9324.JPG: 384x640 25 Humans, 132.1ms\n",
      "Speed: 2.0ms preprocess, 132.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9324.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9287.JPG: 384x640 10 Humans, 147.1ms\n",
      "Speed: 2.2ms preprocess, 147.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9287.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9293.JPG: 384x640 29 Humans, 172.3ms\n",
      "Speed: 6.6ms preprocess, 172.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9293.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9278.JPG: 384x640 11 Humans, 176.7ms\n",
      "Speed: 2.3ms preprocess, 176.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9278.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9343.JPG: 384x640 15 Humans, 141.4ms\n",
      "Speed: 5.4ms preprocess, 141.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9343.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9342.JPG: 384x640 15 Humans, 148.4ms\n",
      "Speed: 2.0ms preprocess, 148.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9342.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9340.JPG: 384x640 14 Humans, 178.1ms\n",
      "Speed: 6.8ms preprocess, 178.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9340.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9341.JPG: 384x640 9 Humans, 134.4ms\n",
      "Speed: 1.9ms preprocess, 134.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9341.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9345.JPG: 384x640 16 Humans, 148.5ms\n",
      "Speed: 2.3ms preprocess, 148.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9345.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9344.JPG: 384x640 10 Humans, 174.0ms\n",
      "Speed: 2.4ms preprocess, 174.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9344.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9346.JPG: 384x640 9 Humans, 157.8ms\n",
      "Speed: 2.7ms preprocess, 157.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9346.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/davidwhite/Yolo_Code/prtm_yolo/datasets/Lake_Anna_Beach/MFDC9347.JPG: 384x640 10 Humans, 194.2ms\n",
      "Speed: 2.9ms preprocess, 194.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1m/Users/davidwhite/Yolo_Code/prtm_yolo/runs/detect/out_beach/annotated_images_roboflow_ersion_4_human_people\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image: MFDC9347.JPG\n",
      "Inference completed for all images.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# YOLO8 class labels based on the .yaml dataset (you can extract this programmatically from model.names)\n",
    "class_names = model.names  # This will contain a list of Yolo8 class names\n",
    "\n",
    "# Creates empty list for CSV data. Each iteration is appended\n",
    "detection_data = []\n",
    "\n",
    "# Filename for the CSV data\n",
    "csv_filename = 'detections.csv'\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        \"\"\" image_path = os.path.join(image_folder, filename) \"\"\"\n",
    "        \"\"\" results = model.predict(source=image_path, save=True) \"\"\"\n",
    "        # \n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        results = model.predict(source=image_path, save=True, project=output_folder, name='annotated_images_roboflow_ersion_4_human_people', exist_ok=True)\n",
    "\n",
    "        # Extract detection details\n",
    "        for result in results:\n",
    "            for detection in result.boxes.data:\n",
    "                x1, y1, x2, y2, confidence, class_id = detection[:6]\n",
    "                class_id = int(class_id.item())\n",
    "                class_name = class_names[class_id] \n",
    "                detection_data.append([filename, x1.item(), y1.item(), x2.item(), y2.item(), confidence.item(), class_id, class_name])\n",
    "\n",
    "                # Save detection results to CSV\n",
    "                with open(csv_filename, 'w', newline='') as csvfile:\n",
    "                    csvwriter = csv.writer(csvfile)\n",
    "                # Write the header\n",
    "                    csvwriter.writerow(['filename','x1', 'y1', 'x2', 'y2', 'confidence', 'class_id', 'class_name'])\n",
    "                # Write detection data\n",
    "                    csvwriter.writerows(detection_data)\n",
    "\n",
    "        print(f\"Processed image: {filename}\")\n",
    "print(\"Inference completed for all images.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
